---
layout: project
description: We created a list of 100 of the most valuable datasets for the city of Berlin
lang: en
title: "Berlin's Core Datasets: About the project"
subtitle: Which datasets offer the greatest value for the city of Berlin when published as open data? 
type: dataset
colorMode: bright
featuredImage: /projects/kerndatensaetze/images/featured.jpg
thumbnail: /projects/kerndatensaetze/images/thumbnail.jpg
heroImage: /projects/kerndatensaetze/images/hero.jpg
socialMediaImage: /projects/kerndatensaetze/social_media.jpg
visible: false
featured: false
authors:
  - victoria-dykes
start: 2019-07-31
end: 2019-07-31
status: finished
date: 2019-07-31  
redirect_from:
  - /projects/datadive_accessibility/index_en.html

---

In an ideal world, all governments would operate as "open by default", meaning all of their data would be made available to citizens as open data (of course with exceptions made for personal data or other particularly sensitive data). There would be no questioning or hand-wringing about what data to publish, because it all simply would be. 

But in Berlin – and in most governments across the globe – we don't live in that ideal world. We live in a world where government resources made available for open data publishing – including the time government employees have to dedicate to open data – are limited, leading to questions of prioritization: If we aren't in a position to simply publish all of the government's data at once, where should we best invest our resources? Which are the datasets a city like Berlin _most_ needs?

This last question was the central one we aimed to answer with our latest project, "Berlin's Core Datasets" (in German: Berlins Kerndatensätze). You can read more about this project in our accompanying publication (available only in German) (LINK), or you can go straight to the list of datasets here (LINK). In this post, we'll go into more detail about how we put the list together. 

Creating the list
--------------------------------------

### Origins

We began this project by assembling a list of all the datasets that we could think of that could be possibly relevant for Berlin. The list was assembled irrespective of whether the data was already available as open data in Berlin or not, as our goal was not to solely assess Berlin's existing open data offerings or the gaps therein.

The basis for the initial list included our own ideas based on our extensive experience working with open data, datasets included in the current draft of Berlin's upcoming open data ordinance, and a preliminary version of the "example data catalog" ("Musterdatenkatalog" in German) [that the Bertelsmann Stiftung developed](https://www.bertelsmann-stiftung.de/de/unsere-projekte/smart-country/projektnachrichten/musterdatenkatalog-welche-offenen-daten-stellen-kommunen-zur-verfuegung/) for the German state of North Rhein-Westphalia. We ended up with a list of more than 200 datasets, but it was important to us to cull this down to a more manageable number – the point of this project was to help give a starting point to discussions of which data Berlin absolutely needs to be publishing, and an overly long list wouldn't provide government employees with a clear starting point.

To reduce the list, we wanted develop a set of semi-objective criteria that we could use to score individual datasets and thus identify the datasets with the highest potential value for Berlin. Accordingly, our first step was thus to see what examples there already were of such approaches. In our subsequent research, we identified two main methodologies for selecting datasets to be published as open data: methodologies for identifying so-called "high-value datasets" and methodologies for scoring and prioritizing datasets for publishing. These are two distinct but ultimately complimentary approaches. For a list of resources we used, please see the "Further Resources" section at the end of this post. 

### The scoring process

Based on all of these resources, we developed our own set of criteria and an accompanying scale. After some initial iterations, we settled on these five criteria to use for scoring datasets: 

* Potential for re-use among **civil society** actors(citizens, NGOs, etc.)
* Potential for re-use among **private sector** actors
* Potential for re-use among **academic researchers** 
* Potential for **efficiency gains** or **cost-savings** for government actors
* Potential of the data for increased **governmental transparency**

For each of these five criteria, we rated the datasets on a 1 - 3 scale, which roughly functioned as follows:

**1:** This dataset has **no clear relevance** for this criterion <br>
**2:** This dataset has **indirect relevance** for this criterion (for example, this data needs to first be connected with other data to be relevant) <br>
**3:** This dataset has a **clear, direct relevance** for this criterion

We then used this scale to rate every dataset in our list of 200+. After many rounds of internal and external deliberation, we were able to land at a final list of 100 datasets which, using our criteria, had the highest scores and which thus (in our opinion) demonstrate the greatest possible value for Berlin. 

For the final list, we also evaluated one additional facet of the data: the current availability of the data (i.e., does the data exist as closed or open data – or does it not exist at all?). We developed an additonal 0 - 4 scale for evaluating the data availability. We decided to develop our own scale here, rather than use an existing one like the 5-Star Model, as we found it important to differentiate between degrees of closedness as well as degrees of openness – scales like the 5-Star Model wouldn't have offered us the nuance we wanted to differentiate between completely closed data, and data that is openly provided in non-machine-readable forms, for example. 

The scale for assessing dataset availability is as follows:

**0:** The data either **does not exist** or its status is **unknown** <br>
**1:** The data exists, but it’s **not publicly accessible** in any form<br>
**2:** The data is **publicly accessible but not machine-readable** (e.g., cases where images of a map are provided rather than proper geospatial data)<br>
**3:** The data is **machine readable but has limitations** (such as insufficient quality or granularity)<br>
**4:** The data is available as  **fully open and high-quality data**

Using the list
--------------------------------------

Our primary goal of this list was to provide a clear direction for open data publishing in Berlin. All too often, when talking with government employees about open data, they express a general support for the topic (or at least acknoweldge they're not explicitly against it), but they struggle to relate the broad call for more open government data to their own work – "Yes, Berlin should publish more data, but what do you want from *me*?"

The list has the added advantage of providing a clearer picture of where there are major gaps – as well as major successes – in Berlin's open data landscape. By sorting our list by "Availability", for example, you can easily see which are the most prominent datasets where there is no open data to date (for example, various traffic-related datasets or data on daycare centers), or where Berlin already has solid open data available (for example, data related to public transit stations or lines, or demographic data).

Further Resources
-----------------

The following are resources from Germany and North America that we used as a basis for our rating methodology for this project. 

Criteria for high-value datasets:

* **[Report on high-value datasets from EU institutions](https://joinup.ec.europa.eu/sites/default/files/document/2014-06/ISA%20Programme%20-%202014%20-%20Report%20on%20high-value%20datasets%20from%20EU%20institutions.pdf)** <br> (EU-issued report, English)
* **[Canada Open Government Working Group: High Value Datasets Criteria](https://joinup.ec.europa.eu/sites/default/files/document/2014-06/ISA%20Programme%20-%202014%20-%20Report%20on%20high-value%20datasets%20from%20EU%20institutions.pdf)** <br> (Federal Government of Canada, English)

Criteria for dataset prioritization:

* **[Open Data Prioritization Toolkit](https://s3.amazonaws.com/sitesusa/wp-content/uploads/sites/1151/filebase/cio_document_library/Open%20Data%20Prioritization%20Toolkit%20Summary.html#toolkit)** <br> (Chief Information Officer Council of the United States, English)
* **[Open Data Handbook](http://ny.github.io/open-data-handbook/guidelines.html)** <br> (State of New York, USA, English)
* **[Montgomery County Government Open Data Implementation Plan](https://montgomerycountymd.gov/open/Resources/Files/OpenDataImplementationPlan_FY14.pdf)** <br> (Montgomery County, Maryland, USA, English)
* **[Strategic Publishing of Open Government Data](https://www.oeffentliche-it.de/documents/10181/14412/Strategische+Bereitstellung+offener+Verwaltungsdaten)** <br> (Center of Excellence for Public IT, Germany, German)
* **[Guide to Requirements for Data Publishing](https://www.bva.bund.de/SharedDocs/Downloads/DE/Behoerden/Beratung/Methoden/open_data_anforderungen_daten.pdf?__blob=publicationFile&v=1)** <br> (German Federal Office of Administration, German)
  
  
